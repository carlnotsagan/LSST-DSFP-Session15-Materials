{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlnotsagan/LSST-DSFP-Session15-Materials/blob/main/fields_intro_to_GPUs_solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quHFe1dTJVan"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division, absolute_import "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuAyY7U9JVbK"
      },
      "source": [
        "# Introduction to GPUs (in Python):\n",
        "\n",
        "By Carl Fields (Los Alamos National Lab)\n",
        "\n",
        "*This exercise was designed heavily based on tutorials from the [GTC 2018 Conference](https://github.com/ContinuumIO/gtc2018-numba).* \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHPCMLpBJVbd"
      },
      "source": [
        "## Problem 0) Creating Our HPC Environment\n",
        "**Before** beginning, we want to prepare a new environment for the purpose of this exercise.\n",
        "\n",
        "Be sure to activate our HPC environment from last time:\n",
        "\n",
        "```linux\n",
        "$ conda activate hpc\n",
        "```\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mb4EgY5YJVbb"
      },
      "source": [
        "## Learning Objectives\n",
        "\n",
        "- Using Numba decorators to speed up algorithms\n",
        "- Using `timeit` profiler for generic algorithm profiling\n",
        "- Creating complex alogrithms utilizing Numba decorators\n",
        "- Using `line_profiler` to expose parallelizable regions in complex algorithms\n",
        "- Creating Numpy Ufuncs\n",
        "- Exploring shared memory parallelism in Numba\n",
        "- Characterizing strong scaling \n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMU9pYvQJVbq"
      },
      "source": [
        "We can check that our installation worked by trying to import the required libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPild-HfJVbs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRApbp_zJVbu"
      },
      "source": [
        "## Problem 1) Exploring a basic algorithm targeting the GPU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1GFBEnNJVb8"
      },
      "source": [
        "We want to begin by compaaring a native numpy function which will leverage the CPU and compare that to a Ufunc that will target the CPU. \n",
        "\n",
        "Lets start by considering the addition of two numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4UTxhKsJVb_"
      },
      "source": [
        "**Problem 1a** Run the following cell to compute the addition of two arrays:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqcpLS9BJVcM",
        "outputId": "0050bf0e-25af-42cd-c424-abec8e51656d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([11, 22, 33, 44])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.array([1, 2, 3, 4])\n",
        "b = np.array([10, 20, 30, 40])\n",
        "\n",
        "np.add(a, b)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "More information on Numpy Ufuncs can be found [here](https://docs.scipy.org/doc/numpy/reference/ufuncs.html)."
      ],
      "metadata": {
        "id": "P_KDgS8TLIIE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we want to explore using Numba to create Ufuncs that target the GPU."
      ],
      "metadata": {
        "id": "HigqTW-4LTRB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 1b** Use the `vectorize` decorator in Numba to write a function that adds to arrays. Use the `int64` data types and `target='cuda'`. Note: An overview including some common terminology for CUDA programming can be found [here](https://numba.readthedocs.io/en/stable/cuda/overview.html)."
      ],
      "metadata": {
        "id": "ZL_tQqRILk8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import vectorize\n",
        "\n",
        "@vectorize(['int64(int64, int64)'], target='cuda')\n",
        "def add_ufunc(x, y):\n",
        "    return x + y"
      ],
      "metadata": {
        "id": "_iSVUWE-MeFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before running we need to be sure we have the hardware we would like to target!\n",
        "\n",
        "First, you'll need to enable GPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select GPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Check that the GPU was found:"
      ],
      "metadata": {
        "id": "byv3W6puNqAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B240Pi_UN34I",
        "outputId": "7f1f2099-fd0f-40d5-e12b-b125c9f445ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "More information can be found about the available types of devices:"
      ],
      "metadata": {
        "id": "mu9dqxDfOruh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hk8mU8y7OXUh",
        "outputId": "809084e8-11e3-4616-e26a-a92f79444fbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 2500660274138816220\n",
              " xla_global_id: -1, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14444920832\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 4334664493303736742\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
              " xla_global_id: 416903419]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 1c** Run your Ufunc which utilizes the GPU and compare the numerical result to Numpy."
      ],
      "metadata": {
        "id": "s39l-vQ2MpBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('a+b:\\n', add_ufunc(a, b))\n",
        "assert np.allclose(np.add(a, b),add_ufunc(a, b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfoLLhlkMoH8",
        "outputId": "6673b2c4-ce3d-45fc-e983-d67e36ae5453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a+b:\n",
            " [11 22 33 44]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, lets use our favorite `timeit` magic command to see how much we benefitted from targeting the GPU.\n"
      ],
      "metadata": {
        "id": "ISBs9a8IPbN-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHdNjXQKJVcP"
      },
      "source": [
        "**Problem 1d** Use `timeit` to compare the execution time of the default Numpy Ufunc and our new Numba Ufunc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty9hOhdFJVcc",
        "outputId": "0ace5af6-a5b0-4898-a6a1-7974c60b241f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 49.62 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1000000 loops, best of 5: 506 ns per loop\n"
          ]
        }
      ],
      "source": [
        "%timeit np.add(a,b)   # NumPy on CPU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit add_ufunc(a,b) # Numba on GPU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHyk6SEnP2LG",
        "outputId": "6a0fe399-08bf-40d0-926a-f29ea839fbc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 loops, best of 5: 1.22 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The GPU result is... *slower*?\n",
        "\n",
        "**Problem 1e** Discuss in this situation why our GPU result may be slower and how we can modify the problem to benfit fromm the GPU."
      ],
      "metadata": {
        "id": "it4I4hqrQQfw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer** \n",
        "\n",
        "Some points to consider: \n",
        "\n",
        " - **Our inputs are too small**: the GPU achieves performance through parallelism, operating on thousands of values at once. Our test inputs have only 4 and 16 integers, respectively. We need a much larger array to even keep the GPU busy.\n",
        "\n",
        "\n",
        "- **Our calculation is too simple**: Sending a calculation to the GPU involves quite a bit of overhead compared to calling a function on the CPU. If our calculation does not involve enough math operations (often called \"arithmetic intensity\"), then the GPU will spend most of its time waiting for data to move around.\n",
        "\n",
        "\n",
        "- **We copy the data to and from the GPU**: While including the copy time can be realistic for a single function, often we want to run several GPU operations in sequence. In those cases, it makes sense to send data to the GPU and keep it there until all of our processing is complete.\n",
        "\n",
        "\n",
        "- **Our data types are larger than necessary**: Our example uses int64 when we probably don't need it. "
      ],
      "metadata": {
        "id": "8j-yapHRQiVU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 2) Exploring a more complex, data-intensive algorithm targeting the GPU"
      ],
      "metadata": {
        "id": "q8Pip2rbRoEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now consider a more complex example where we can take some of the necessary steps to make the problem more efficient to run on GPUs. A few of these steps include: \n",
        "\n",
        "1. Using native math module functions described [here](https://docs.python.org/3/library/math.html).\n",
        "2. Using a less precise datatype than necessary. Consider using `float32` instead. \n",
        "3. Solving a more complex algorithm - one with more math operations in this case than the addition of two arrays. \n",
        "4. Precompute constant values when possible.\n"
      ],
      "metadata": {
        "id": "2iy_vIiXRzA7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 2a** Take the above steps to define the Ufunc for a Gaussian PDF using Numba `vectorize` again targeting `cuda`: \n",
        "\n",
        " $f(x) = \\frac{1}{\\sigma \\sqrt{\\pi}} e^{-\\frac{1}{2} \\left ( \\frac{x-\\mu}{\\sigma} \\right )^{2}}$.\n",
        "\n",
        " Information on solving Normal distributions are discussed [here](https://en.wikipedia.org/wiki/Normal_distribution).[link text](https://)"
      ],
      "metadata": {
        "id": "olNN1JTwTFNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math  # Note that for the CUDA target, we need to use the scalar functions from the math module, not NumPy\n",
        "\n",
        "SQRT_2PI = np.float32((2*math.pi)**0.5)  # Precompute this constant as a float32.  Numba will inline it at compile time.\n",
        "\n",
        "@vectorize(['float32(float32, float32, float32)'], target='cuda')\n",
        "def gaussian_pdf(x, mean, sigma):\n",
        "    '''Compute the value of a Gaussian probability density function at x with given mean and sigma.'''\n",
        "    return math.exp(-0.5 * ((x - mean) / sigma)**2) / (sigma * SQRT_2PI)"
      ],
      "metadata": {
        "id": "VYyEI4LrRx5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 2b** Evaluate our Ufunc a million times, set $\\mu=0$ and $\\sigma=1$. Use `np.random.uniform` to create our `x` array for a bound of [-3,3].: "
      ],
      "metadata": {
        "id": "p8uM5sPSUR0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Gaussian a million times!\n",
        "x = np.random.uniform(-3, 3, size=1000000).astype(np.float32)\n",
        "mean = np.float32(0.0)\n",
        "sigma = np.float32(1.0)\n",
        "\n",
        "# Quick test\n",
        "gaussian_pdf(x[0], 0.0, 1.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxNO39mtUSfx",
        "outputId": "9ba39679-6445-4fd6-c255-310636288a55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00636183], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 2c** Perform the same calculation using scipys native `norm` function (details [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html)). Time the results using `timeit`.[link text](https://)"
      ],
      "metadata": {
        "id": "MuyzndFdU5sZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats # for definition of gaussian distribution\n",
        "norm_pdf = scipy.stats.norm\n",
        "%timeit norm_pdf.pdf(x, loc=mean, scale=sigma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuTYq6gjUz2I",
        "outputId": "600e5257-fdad-4b71-f521-6b1f433afe2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 37.5 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 2d** Time the result for our GPU Ufunc for comparison:"
      ],
      "metadata": {
        "id": "B7JZNpAwVVpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit gaussian_pdf(x, mean, sigma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0J0hlysUVWN6",
        "outputId": "59bf539f-dbf0-42b7-baa2-b3df5408b8ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 35.46 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "100 loops, best of 5: 5.34 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 2e** Thats a big improvement! \n",
        "\n",
        "Discuss some of the overhead costs still associated with this approach.\n",
        "\n",
        "**Answer**: Copying data to and from the GPU."
      ],
      "metadata": {
        "id": "-0FrZT5VVlgG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 3) Memory Management "
      ],
      "metadata": {
        "id": "_iOIEzs_Wgsj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 4) Writing CUDA Kernels"
      ],
      "metadata": {
        "id": "H-WXt2f9YymF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Problem 5) Matrix multiplication (Optional/Challenge)"
      ],
      "metadata": {
        "id": "ds3xczZIdmdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "foBwP9I2drcn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "colab": {
      "name": "fields_intro_to_GPUs_solutions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}